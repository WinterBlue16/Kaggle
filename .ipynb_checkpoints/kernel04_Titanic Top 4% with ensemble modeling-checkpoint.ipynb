{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Top 4% with ensemble modeling \n",
    "<br>\n",
    "\n",
    "## Yassine Ghouzam, PhD\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "13/07/2017\n",
    "- **1 Introduction**\n",
    "- **2 Load and check data**\n",
    "    - 2.1 load data \n",
    "    - 2.2 Outlier detection \n",
    "    - 2.3 joining train and test set\n",
    "    - 2.4 check for null and missing values \n",
    "- **3 Feature analysis**\n",
    "    - 3.1 Numerical values \n",
    "    - 3.2 Categorical values\n",
    "- **4 Filling missing Values**\n",
    "    - 4.1 Age\n",
    "- **5 Feature engineering** \n",
    "    - 5.1 Name/Title\n",
    "    - 5.2 Family Size\n",
    "    - 5.3 Cabin \n",
    "    - 5.4 Ticket\n",
    "- **6 Modeling** \n",
    "    - 6.1 Simple modeling \n",
    "        - 6.1.1 Cross validate models\n",
    "        - 6.1.2 Hyperparameter tunning for best models\n",
    "        - 6.1.3 Plot learning curves\n",
    "        - 6.1.4 Feature importance of the tree based classifiers \n",
    "     - 6.2 Ensemble modeling \n",
    "         - 6.2.1 Combining models\n",
    "     - 6.3 Prediction \n",
    "         - 6.3.1 Predict and Submit results\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "## 1. Introduction \n",
    "<br>\n",
    "This is my first kernel at Kaggle. I choosed the Titanic competition which is a good way to introduce feature engineering and ensemble modeling. Firstly, I will display some feature analyses then ill focus on the feature engineering. Last part concerns modeling and predicting the survival on the Titanic using and voting procedure. \n",
    "<br>\n",
    "\n",
    "This script follows three main parts:\n",
    "<br>\n",
    "\n",
    "- Feature analysis\n",
    "- Feature engineering \n",
    "- Modeling \n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve\n",
    "\n",
    "sns.set(style='white', context='notebook', palette='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and check data\n",
    "<br>\n",
    "\n",
    "### 2.1 Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data \n",
    "##### Load train and Test\n",
    "\n",
    "train = pd.read_csv('/kaggle/input/titanic/train.csv')\n",
    "test = pd.read_csv('/kaggle/input/titanic/test.csv')\n",
    "IDtest = test['PassengerID']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Outlier detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier detection \n",
    "\n",
    "def detect_outliers(df, n, features):\n",
    "    '''\n",
    "    Takes a dataframe df of features and returns a list the indices\n",
    "    corresponding to the observations containing more than n outliers according to the Tukey method.\n",
    "    '''\n",
    "    outlier_indices=[]\n",
    "    \n",
    "    # iterate over features(columns)\n",
    "    for col in features:\n",
    "        # 1st quartile (25%)\n",
    "        Q1 = np.percentile(df[col], 25)\n",
    "        # 3rd quartile (75%)\n",
    "        Q3 = np.percentile(df[col], 75)\n",
    "        # Interquartile range(IQR)\n",
    "        IQR = Q3-Q1\n",
    "        \n",
    "        # outlier step\n",
    "        outlier_step = 1.5 * IQR\n",
    "        \n",
    "        # Determine a list of indices of outliers for feature col\n",
    "        outlier_list_col = df[(df[col] < Q1 - outlier_step) | (df[col] > Q3 + outlier_step)].index\n",
    "        \n",
    "        # append the found outlier indices for col to the list of outlier indices\n",
    "        outlier_indices = Counter(outlier_indices)\n",
    "        multiple_outliers = list(k for k, v in outlier_indices.items() if v > n)\n",
    "        \n",
    "        return multiple_outliers\n",
    "    \n",
    "    # detect outliers from Age, SibSp, Parch and Fare\n",
    "    Outliers_to_drop = detect_outliers(train, 2, ['Age', 'SibSp', 'Parch', 'Fare'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since outliers can have a dramatic effect on the prediction(espacially for regression problems), I choosed to manage them. \n",
    "<br>\n",
    "\n",
    "I used the Tukey method(Tukey JW, 1977) to detect outliers which defines an interquartile range comprised between the 1st and 3rd quartile of the distribution values(IQR). An outlier is a row that have a feature value outside the (IQR +- an outlier step).\n",
    "<br>\n",
    "\n",
    "I decided to detect outliers from the numerical values feature(Age, SibSp, Sarch and Fare).Then, i considered outliers as rows that have at least two outlied numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[Outliers_to_drop] # show the outliers row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We detect 10 outliers. The 28, 89 and 342 passenger have an high Ticket Fare The 7 others have very high values of SibSP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop outliers\n",
    "train = train.drop(Outliers_to_drop).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 joining train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Join train and test datasets in order to obtain the same number of features during categorical conversion\n",
    "train_len = len(train)\n",
    "dataset = pd.concat(objs=[train, test], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 check for null and missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill empty and NaNs values with NaN\n",
    "dataset = dataset.fillna(np.nan)\n",
    "\n",
    "# Check for null values\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age and Cabin features have an important part of missing values.\n",
    "<br>\n",
    "\n",
    "**Survived missing values correspond to the join testing dataset(Survived column doesn't exist in test set and has been replace by NaN values when concatenating the train and test set)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infos\n",
    "train.info()\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Summerize data\n",
    "# Summerize and statistics\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature analysis\n",
    "<br>\n",
    "\n",
    "### 3.1 Numerical values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix between numerical values (SibSp Parch Age and Fare values) and Survived\n",
    "g = sns.heatmap(train[[\"Survived\", \"SibSp\", \"Parch\", \"Age\", \"Fare\"]].corr(), annot=True, fmt=\".2f\", cmap=\"coolwarm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only Fare feature seems to have a significative correlation with the survival probability.\n",
    "<br>\n",
    "\n",
    "It doesn't mean that the other features are not useful. Subpopulations in these features can be correlated with the survival. To determine this, we need to explore in detail these features\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "**SibSP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore SibSp feature vs Survived\n",
    "g = sns.factorplot(x=\"SibSp\", y=\"Survived\", data=train, kind=\"bar\", size=6, palette='muted')\n",
    "g.despine(left=True)\n",
    "g=g.set_ylabels(\"Survived probability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that passengers having a lot of siblings/spouses have less chance to survive\n",
    "<br>\n",
    "\n",
    "Single passengers(0 SibSP) or with two other persons(SibSP 1 or 2) have more chance to survive\n",
    "<br>\n",
    "\n",
    "This observation is quite interestin, we can consider a new feature describing these categories(See feature engineering)\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "**Parch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore Parch feature vs Survived\n",
    "g = sns.factorplot(x='Parch', y='Survived', data=train, kind='bar', size=6, palette='muted')\n",
    "g.despine(left=True)\n",
    "g = g.set_ylabels('survived probability')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small families have more chance to survive, more than single(Parch 0), medium(Parch 3, 4) and large families(Parch 5, 6).\n",
    "<br>\n",
    "\n",
    "Be careful there is an important standard deviation in the survival of passengers with 3 parents/children\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "**Age**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore Age vs Survived\n",
    "g = sns.FaceGrid(train, col='Survived')\n",
    "g = g.map(sns.distplot, 'Age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age distribution seems to be a tailed distribution, maybe a gaussian distribution.\n",
    "<br>\n",
    "\n",
    "We notice that age distributions are not the same in the survived and not survived subpopulations. Indeed, there is a peak corresponding to young passengers, that have survived. We also see that passengers between 60-80 have less survived.\n",
    "<br>\n",
    "\n",
    "So, even if \"Age\" is not correlated with \"Survived\", we can see that there is age categories of passengers that of have more or less chance to survive.\n",
    "<br>\n",
    "\n",
    "It seems that very young passengers have more chance to survive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore Age distribution \n",
    "g = sns.kdeplot(train[\"Age\"][(train[\"Survived\"]==0) & (train[\"Age\"].notnull())], color=\"Red\", shade=True)\n",
    "g = sns.kdeplot(train['Age'][(train['Survived']==1) & (train[\"Age\"].notnull())], ax=g, color=\"Blue\", shade=True)\n",
    "g.set_xlabel(\"Age\")\n",
    "g.set_ylabel(\"Frequency\")\n",
    "g = g.legend([\"Not Survived\", \"Survived\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
